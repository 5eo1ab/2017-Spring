{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $k$-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# random data generation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "n=50\n",
    "np.random.seed(20)\n",
    "x=np.random.rand(n)-0.5\n",
    "y=np.random.rand(n)-0.5\n",
    "train=pd.DataFrame(data={'x':x,'y':y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 위의 생성한 데이터 중에서 (0,0)의 10 nearest neighbor를 찾으시오. 10 nearest neighbor의 python 기준의 index를 쓰시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088131</td>\n",
       "      <td>0.234301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.397714</td>\n",
       "      <td>-0.091357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.391531</td>\n",
       "      <td>0.278688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.315837</td>\n",
       "      <td>0.303971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.464110</td>\n",
       "      <td>0.286071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y\n",
       "0  0.088131  0.234301\n",
       "1  0.397714 -0.091357\n",
       "2  0.391531  0.278688\n",
       "3  0.315837  0.303971\n",
       "4 -0.464110  0.286071"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['distance'] = np.sqrt(x**2+y**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45, 29, 47, 26,  7,  8, 25,  6,  5, 37])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sort_values('distance').index.values[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 전체 데이터와 (0, 0)에 대한 scatter plot을 그리시오. 이 때 (0,0)은 무작위로 생성한 데이터와 구분되도록 하고, 10 nearest neighbor의 경우에도 nearest neighbor가 아닌 포인트와 구분되도록 scatter plot을 그리시오. (색이나 모양으로 구별)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_knn = train.sort_values('distance').index.values[:10]\n",
    "idx_others = train.sort_values('distance').index.values[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x10dd84f60>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCAAAUFIEAAAoKQIAAJQUAQAASur/AdZOUL8DlLo5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10dea8a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(0,0, marker='+')\n",
    "plt.scatter(x[idx_knn], y[idx_knn], marker=\"*\")\n",
    "plt.scatter(x[idx_others], y[idx_others])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 기존 데이터에서 y축의 값을 5배한 다음에 다시 (0,0)의 10 nearest neighbor를 찾으시오. 이 때 거리는 유클리디안 거리를 사용하고 10 nearest neighbor의 python 기준의 index를 쓰시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['y_re'] = train['y']*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>distance</th>\n",
       "      <th>y_re</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088131</td>\n",
       "      <td>0.234301</td>\n",
       "      <td>0.250327</td>\n",
       "      <td>1.171503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.397714</td>\n",
       "      <td>-0.091357</td>\n",
       "      <td>0.408071</td>\n",
       "      <td>-0.456783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.391531</td>\n",
       "      <td>0.278688</td>\n",
       "      <td>0.480586</td>\n",
       "      <td>1.393440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.315837</td>\n",
       "      <td>0.303971</td>\n",
       "      <td>0.438351</td>\n",
       "      <td>1.519853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.464110</td>\n",
       "      <td>0.286071</td>\n",
       "      <td>0.545193</td>\n",
       "      <td>1.430357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y  distance      y_re\n",
       "0  0.088131  0.234301  0.250327  1.171503\n",
       "1  0.397714 -0.091357  0.408071 -0.456783\n",
       "2  0.391531  0.278688  0.480586  1.393440\n",
       "3  0.315837  0.303971  0.438351  1.519853\n",
       "4 -0.464110  0.286071  0.545193  1.430357"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['distance_re'] = np.sqrt(x**2+train['y_re']**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>distance</th>\n",
       "      <th>y_re</th>\n",
       "      <th>distance_re</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088131</td>\n",
       "      <td>0.234301</td>\n",
       "      <td>0.250327</td>\n",
       "      <td>1.171503</td>\n",
       "      <td>1.174813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.397714</td>\n",
       "      <td>-0.091357</td>\n",
       "      <td>0.408071</td>\n",
       "      <td>-0.456783</td>\n",
       "      <td>0.605662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.391531</td>\n",
       "      <td>0.278688</td>\n",
       "      <td>0.480586</td>\n",
       "      <td>1.393440</td>\n",
       "      <td>1.447401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.315837</td>\n",
       "      <td>0.303971</td>\n",
       "      <td>0.438351</td>\n",
       "      <td>1.519853</td>\n",
       "      <td>1.552323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.464110</td>\n",
       "      <td>0.286071</td>\n",
       "      <td>0.545193</td>\n",
       "      <td>1.430357</td>\n",
       "      <td>1.503769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y  distance      y_re  distance_re\n",
       "0  0.088131  0.234301  0.250327  1.171503     1.174813\n",
       "1  0.397714 -0.091357  0.408071 -0.456783     0.605662\n",
       "2  0.391531  0.278688  0.480586  1.393440     1.447401\n",
       "3  0.315837  0.303971  0.438351  1.519853     1.552323\n",
       "4 -0.464110  0.286071  0.545193  1.430357     1.503769"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45, 26, 10,  9, 18,  8, 47,  5, 15, 49])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sort_values('distance_re').index.values[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) y축의 값을 5배한 데이터와 (0, 0)에 대한 scatter plot을 그리시오. 이 때 (0,0)은 무작위로 생성한 데이터와 구분되도록 하고, 10 nearest neighbor의 경우에도 nearest neighbor가 아닌 포인트와 구분되도록 scatter plot을 그리시오. (색이나 모양으로 구별) y축의 값을 변경한 후 어떻게 달라졌는지 쓰시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_knn = train.sort_values('distance_re').index.values[:10]\n",
    "idx_others = train.sort_values('distance_re').index.values[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x10dc4f9b0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10de98a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(0,0, marker='+')\n",
    "plt.scatter(x[idx_knn], train['y_re'][idx_knn], marker=\"*\")\n",
    "plt.scatter(x[idx_others], train['y_re'][idx_others])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) decision tree를 학습하는 단계에서 overfitting을 막기 위해서 여러 parameter를 이용하는데 어떤 조합이 가장 좋은지 stratified k-fold cross-validation을 이용해서 알아보고자 한다.  변경하고자 하는 옵션은 max_depth, min_samples_split, min_samples_leaf 이고 사용하게 될 값은 다음과 같다. \n",
    "- max_depth=[3, 4]\n",
    "- min_samples_split=[100, 200, 300]\n",
    "- min_samples_leaf=[50, 100]\n",
    "\n",
    "### 위의 세 옵션에 대해서 5-fold cross-validation을 정확도를 기준으로 수행한다고 했을 때 아래 표에 각 validation step마다 validation set에 의한 정확도를 채우시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail   ...    char_freq_;  char_freq_(  \\\n",
       "0             0.00            0.00   ...           0.00        0.000   \n",
       "1             0.00            0.94   ...           0.00        0.132   \n",
       "2             0.64            0.25   ...           0.01        0.143   \n",
       "3             0.31            0.63   ...           0.00        0.137   \n",
       "4             0.31            0.63   ...           0.00        0.135   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778        0.000        0.000   \n",
       "1          0.0        0.372        0.180        0.048   \n",
       "2          0.0        0.276        0.184        0.010   \n",
       "3          0.0        0.137        0.000        0.000   \n",
       "4          0.0        0.135        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  target  \n",
       "0                       278       1  \n",
       "1                      1028       1  \n",
       "2                      2259       1  \n",
       "3                       191       1  \n",
       "4                       191       1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_table(\"./spambase.txt\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colnames = list(data.columns.values)[:-1]\n",
    "X = data[colnames]\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "idx_train, idx_test = [], []\n",
    "for train, test in skf.split(X, y) :\n",
    "    idx_train.append(train)\n",
    "    idx_test.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'max_depth': 3, 'min_samples_leaf': 50, 'min_samples_split': 100},\n",
       " {'max_depth': 3, 'min_samples_leaf': 100, 'min_samples_split': 100},\n",
       " {'max_depth': 3, 'min_samples_leaf': 50, 'min_samples_split': 200},\n",
       " {'max_depth': 3, 'min_samples_leaf': 100, 'min_samples_split': 200},\n",
       " {'max_depth': 3, 'min_samples_leaf': 50, 'min_samples_split': 300},\n",
       " {'max_depth': 3, 'min_samples_leaf': 100, 'min_samples_split': 300},\n",
       " {'max_depth': 4, 'min_samples_leaf': 50, 'min_samples_split': 100},\n",
       " {'max_depth': 4, 'min_samples_leaf': 100, 'min_samples_split': 100},\n",
       " {'max_depth': 4, 'min_samples_leaf': 50, 'min_samples_split': 200},\n",
       " {'max_depth': 4, 'min_samples_leaf': 100, 'min_samples_split': 200},\n",
       " {'max_depth': 4, 'min_samples_leaf': 50, 'min_samples_split': 300},\n",
       " {'max_depth': 4, 'min_samples_leaf': 100, 'min_samples_split': 300}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth=[3, 4]\n",
    "min_samples_split=[100, 200, 300]\n",
    "min_samples_leaf=[50, 100]\n",
    "params = [dict(max_depth=d, min_samples_split=s, min_samples_leaf=l) \n",
    "          for d in max_depth for s in min_samples_split for l in min_samples_leaf]\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'min_samples_split': 100, 'min_samples_leaf': 50} 0.865237080857\n",
      "{'max_depth': 3, 'min_samples_split': 100, 'min_samples_leaf': 100} 0.857414292786\n",
      "{'max_depth': 3, 'min_samples_split': 200, 'min_samples_leaf': 50} 0.865237080857\n",
      "{'max_depth': 3, 'min_samples_split': 200, 'min_samples_leaf': 100} 0.857414292786\n",
      "{'max_depth': 3, 'min_samples_split': 300, 'min_samples_leaf': 50} 0.865237080857\n",
      "{'max_depth': 3, 'min_samples_split': 300, 'min_samples_leaf': 100} 0.854156963796\n",
      "{'max_depth': 4, 'min_samples_split': 100, 'min_samples_leaf': 50} 0.878262616095\n",
      "{'max_depth': 4, 'min_samples_split': 100, 'min_samples_leaf': 100} 0.861517085913\n",
      "{'max_depth': 4, 'min_samples_split': 200, 'min_samples_leaf': 50} 0.880438894658\n",
      "{'max_depth': 4, 'min_samples_split': 200, 'min_samples_leaf': 100} 0.861517085913\n",
      "{'max_depth': 4, 'min_samples_split': 300, 'min_samples_leaf': 50} 0.880003638946\n",
      "{'max_depth': 4, 'min_samples_split': 300, 'min_samples_leaf': 100} 0.868923521885\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "result_acc = []\n",
    "result_kfold = []\n",
    "for p in params :\n",
    "    clf = DecisionTreeClassifier(\n",
    "                            max_depth = p['max_depth'], \n",
    "                            min_samples_leaf = p['min_samples_leaf'],\n",
    "                            min_samples_split = p['min_samples_split']\n",
    "    )\n",
    "    tmp_acc = []\n",
    "    for k in range(len(idx_train)) :\n",
    "        clf.fit(X.iloc[idx_train[k]], y[idx_train[k]])\n",
    "        tmp_acc.append(clf.score(X.iloc[idx_test[k]], y[idx_test[k]]))\n",
    "    result_acc.append([p['max_depth'], p['min_samples_split'], p['min_samples_leaf']]+tmp_acc)\n",
    "    res = np.array(tmp_acc).mean()\n",
    "    result_kfold.append([p['max_depth'], p['min_samples_split'], p['min_samples_leaf'], res])\n",
    "    print(p, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>Fold1</th>\n",
       "      <th>Fold2</th>\n",
       "      <th>Fold3</th>\n",
       "      <th>Fold4</th>\n",
       "      <th>Fold5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.850163</td>\n",
       "      <td>0.879479</td>\n",
       "      <td>0.888165</td>\n",
       "      <td>0.914037</td>\n",
       "      <td>0.794342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.836048</td>\n",
       "      <td>0.874050</td>\n",
       "      <td>0.880565</td>\n",
       "      <td>0.902067</td>\n",
       "      <td>0.794342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>0.850163</td>\n",
       "      <td>0.879479</td>\n",
       "      <td>0.888165</td>\n",
       "      <td>0.914037</td>\n",
       "      <td>0.794342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>0.836048</td>\n",
       "      <td>0.874050</td>\n",
       "      <td>0.880565</td>\n",
       "      <td>0.902067</td>\n",
       "      <td>0.794342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>0.850163</td>\n",
       "      <td>0.879479</td>\n",
       "      <td>0.888165</td>\n",
       "      <td>0.914037</td>\n",
       "      <td>0.794342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>0.825190</td>\n",
       "      <td>0.868621</td>\n",
       "      <td>0.880565</td>\n",
       "      <td>0.902067</td>\n",
       "      <td>0.794342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.892508</td>\n",
       "      <td>0.895765</td>\n",
       "      <td>0.903366</td>\n",
       "      <td>0.898803</td>\n",
       "      <td>0.800871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.878393</td>\n",
       "      <td>0.890337</td>\n",
       "      <td>0.895765</td>\n",
       "      <td>0.894450</td>\n",
       "      <td>0.748640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>0.892508</td>\n",
       "      <td>0.895765</td>\n",
       "      <td>0.903366</td>\n",
       "      <td>0.906420</td>\n",
       "      <td>0.804135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>0.878393</td>\n",
       "      <td>0.890337</td>\n",
       "      <td>0.895765</td>\n",
       "      <td>0.894450</td>\n",
       "      <td>0.748640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>0.892508</td>\n",
       "      <td>0.895765</td>\n",
       "      <td>0.903366</td>\n",
       "      <td>0.914037</td>\n",
       "      <td>0.794342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>0.867535</td>\n",
       "      <td>0.884908</td>\n",
       "      <td>0.895765</td>\n",
       "      <td>0.902067</td>\n",
       "      <td>0.794342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_samples_split  min_samples_leaf     Fold1     Fold2  \\\n",
       "0           3                100                50  0.850163  0.879479   \n",
       "1           3                100               100  0.836048  0.874050   \n",
       "2           3                200                50  0.850163  0.879479   \n",
       "3           3                200               100  0.836048  0.874050   \n",
       "4           3                300                50  0.850163  0.879479   \n",
       "5           3                300               100  0.825190  0.868621   \n",
       "6           4                100                50  0.892508  0.895765   \n",
       "7           4                100               100  0.878393  0.890337   \n",
       "8           4                200                50  0.892508  0.895765   \n",
       "9           4                200               100  0.878393  0.890337   \n",
       "10          4                300                50  0.892508  0.895765   \n",
       "11          4                300               100  0.867535  0.884908   \n",
       "\n",
       "       Fold3     Fold4     Fold5  \n",
       "0   0.888165  0.914037  0.794342  \n",
       "1   0.880565  0.902067  0.794342  \n",
       "2   0.888165  0.914037  0.794342  \n",
       "3   0.880565  0.902067  0.794342  \n",
       "4   0.888165  0.914037  0.794342  \n",
       "5   0.880565  0.902067  0.794342  \n",
       "6   0.903366  0.898803  0.800871  \n",
       "7   0.895765  0.894450  0.748640  \n",
       "8   0.903366  0.906420  0.804135  \n",
       "9   0.895765  0.894450  0.748640  \n",
       "10  0.903366  0.914037  0.794342  \n",
       "11  0.895765  0.902067  0.794342  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame as df\n",
    "colnames = ['max_depth', 'min_samples_split', 'min_samples_leaf', 'Fold1', 'Fold2', 'Fold3', 'Fold4', 'Fold5']\n",
    "result_acc = df(result_acc, columns=colnames)\n",
    "result_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>Acc_Fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.865237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.857414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>0.865237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>0.857414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>0.865237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>0.854157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.878263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.861517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>0.880439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>0.861517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>0.880004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>0.868924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_samples_split  min_samples_leaf  Acc_Fold\n",
       "0           3                100                50  0.865237\n",
       "1           3                100               100  0.857414\n",
       "2           3                200                50  0.865237\n",
       "3           3                200               100  0.857414\n",
       "4           3                300                50  0.865237\n",
       "5           3                300               100  0.854157\n",
       "6           4                100                50  0.878263\n",
       "7           4                100               100  0.861517\n",
       "8           4                200                50  0.880439\n",
       "9           4                200               100  0.861517\n",
       "10          4                300                50  0.880004\n",
       "11          4                300               100  0.868924"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames= colnames[:3] + ['Acc_Fold']\n",
    "result_kfold = df(result_kfold, columns=colnames)\n",
    "result_kfold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 평균적으로 가장 정확도가 높은 조건으로 전체 데이터를 이용해서 decision tree를 학습하고 그 결과 tree를 그리시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>Acc_Fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>0.880439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  min_samples_split  min_samples_leaf  Acc_Fold\n",
       "8          4                200                50  0.880439"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = result_kfold[result_kfold['Acc_Fold']==np.max(result_kfold['Acc_Fold'])]\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4, 'min_samples_leaf': 50, 'min_samples_split': 200}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_param = params[res_df.index.values[0]]\n",
    "res_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=50,\n",
       "            min_samples_split=200, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(\n",
    "                            max_depth = res_param['max_depth'], \n",
    "                            min_samples_leaf = res_param['min_samples_leaf'],\n",
    "                            min_samples_split = res_param['min_samples_split']\n",
    "    )\n",
    "clf.fit(X,y)\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) sklearn.model_selection.train_test_split을 이용해서 데이터를 train set과 test set (validation set)으로 나누고자 한다. 먼저 주어진 데이터를 불러와 input에 해당하는 X와 output 값만 담고 있는 y 변수를 생성하고 여기서부터 train_test_split를 이용해서 Xtrain, Xtest, ytrain, ytest를 얻으시오. 이 때 test_size=0.2, stratify=y, random_state=150으로 설정하시오. Xtrain에 들어있는 데이터 중 맨 위에 있는 5개 데이터와 Xtest에 들어있는 데이터 중 맨 위에 있는 5개 데이터를 jupyter notebook 화면에 print하시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alreadi</th>\n",
       "      <th>also</th>\n",
       "      <th>alway</th>\n",
       "      <th>amp</th>\n",
       "      <th>anyth</th>\n",
       "      <th>around</th>\n",
       "      <th>ask</th>\n",
       "      <th>award</th>\n",
       "      <th>babe</th>\n",
       "      <th>back</th>\n",
       "      <th>...</th>\n",
       "      <th>win</th>\n",
       "      <th>wish</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>would</th>\n",
       "      <th>www</th>\n",
       "      <th>ya</th>\n",
       "      <th>ye</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3205</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3923</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      alreadi  also  alway  amp  anyth  around  ask  award  babe  back  ...   \\\n",
       "989         0     0      0    0      0       0    0      0     0     0  ...    \n",
       "2140        0     0      0    0      0       0    0      0     0     0  ...    \n",
       "3205        0     0      0    1      0       1    0      0     0     0  ...    \n",
       "1263        0     0      0    0      0       0    0      0     0     0  ...    \n",
       "3923        0     0      0    0      0       0    0      0     0     0  ...    \n",
       "\n",
       "      win  wish  word  work  would  www  ya  ye  yeah  year  \n",
       "989     0     0     0     0      0    0   0   0     0     0  \n",
       "2140    0     0     0     0      0    0   0   0     0     0  \n",
       "3205    0     0     0     0      0    0   0   0     0     0  \n",
       "1263    0     0     0     0      0    0   0   0     0     0  \n",
       "3923    0     0     0     0      0    0   0   0     0     0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./spam_sms.csv')\n",
    "\n",
    "colnames = list(data.columns.values)[:-1]\n",
    "X = data[colnames]\n",
    "y = data['target']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.32, random_state=150, stratify=y\n",
    ")\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alreadi</th>\n",
       "      <th>also</th>\n",
       "      <th>alway</th>\n",
       "      <th>amp</th>\n",
       "      <th>anyth</th>\n",
       "      <th>around</th>\n",
       "      <th>ask</th>\n",
       "      <th>award</th>\n",
       "      <th>babe</th>\n",
       "      <th>back</th>\n",
       "      <th>...</th>\n",
       "      <th>win</th>\n",
       "      <th>wish</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>would</th>\n",
       "      <th>www</th>\n",
       "      <th>ya</th>\n",
       "      <th>ye</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3881</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3889</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4437</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      alreadi  also  alway  amp  anyth  around  ask  award  babe  back  ...   \\\n",
       "3881        0     0      0    0      0       1    0      0     0     0  ...    \n",
       "283         0     0      0    0      0       0    0      0     0     0  ...    \n",
       "1134        0     0      0    0      0       0    0      0     0     0  ...    \n",
       "3889        0     0      0    0      0       0    0      0     0     0  ...    \n",
       "4437        0     0      0    0      0       0    0      0     0     0  ...    \n",
       "\n",
       "      win  wish  word  work  would  www  ya  ye  yeah  year  \n",
       "3881    0     0     0     0      0    0   0   0     0     0  \n",
       "283     0     0     0     0      0    0   0   0     0     0  \n",
       "1134    0     0     0     0      0    0   0   0     0     0  \n",
       "3889    0     0     0     0      0    0   0   0     0     0  \n",
       "4437    0     0     0     0      0    0   0   0     0     0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Multinomial naïve Bayes 모형을 이용해서 세팅이 변경없이 train set으로 학습을 하고 test set을 이용해서 정확도(accuracy), recall, precision, f1 measure 값을 구하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.96880733944954134, 'precision': 0.87854251012145745, 'recall': 0.91176470588235292, 'f1_score': 0.89484536082474231}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "res = dict(\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred),\n",
    "    precision = metrics.precision_score(y_test, y_pred),\n",
    "    recall = metrics.recall_score(y_test, y_pred),\n",
    "    f1_score = metrics.f1_score(y_test, y_pred)\n",
    ")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 학습된 Multinomial naïve Bayes 모형으로부터 서로 다른 두 group(스팸 SMS와 스팸이 아닌 SMS)일 확률을 높이는데 가장 기여를 많이 하는 단어 상위 10개씩을 찾으시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res_df = df({'feature':X_train.columns.values,\n",
    "            'log_prob_0' : clf.feature_log_prob_[0],\n",
    "             'log_prob_1' : clf.feature_log_prob_[1],\n",
    "             'prob_0' : np.exp(clf.feature_log_prob_[0]),\n",
    "             'prob_1' : np.exp(clf.feature_log_prob_[1])\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>log_prob_0</th>\n",
       "      <th>log_prob_1</th>\n",
       "      <th>prob_0</th>\n",
       "      <th>prob_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alreadi</td>\n",
       "      <td>-5.230039</td>\n",
       "      <td>-7.453562</td>\n",
       "      <td>0.005353</td>\n",
       "      <td>0.000579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>also</td>\n",
       "      <td>-5.432563</td>\n",
       "      <td>-7.048097</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.000869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alway</td>\n",
       "      <td>-5.858647</td>\n",
       "      <td>-8.146709</td>\n",
       "      <td>0.002855</td>\n",
       "      <td>0.000290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amp</td>\n",
       "      <td>-5.230039</td>\n",
       "      <td>-8.146709</td>\n",
       "      <td>0.005353</td>\n",
       "      <td>0.000290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anyth</td>\n",
       "      <td>-5.246846</td>\n",
       "      <td>-8.146709</td>\n",
       "      <td>0.005264</td>\n",
       "      <td>0.000290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature  log_prob_0  log_prob_1    prob_0    prob_1\n",
       "0  alreadi   -5.230039   -7.453562  0.005353  0.000579\n",
       "1     also   -5.432563   -7.048097  0.004372  0.000869\n",
       "2    alway   -5.858647   -8.146709  0.002855  0.000290\n",
       "3      amp   -5.230039   -8.146709  0.005353  0.000290\n",
       "4    anyth   -5.246846   -8.146709  0.005264  0.000290"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>log_prob_0</th>\n",
       "      <th>prob_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>go</td>\n",
       "      <td>-3.634024</td>\n",
       "      <td>0.026410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>get</td>\n",
       "      <td>-3.763701</td>\n",
       "      <td>0.023198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>gt</td>\n",
       "      <td>-3.869062</td>\n",
       "      <td>0.020878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>lt</td>\n",
       "      <td>-3.881965</td>\n",
       "      <td>0.020610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>call</td>\n",
       "      <td>-3.935311</td>\n",
       "      <td>0.019540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>come</td>\n",
       "      <td>-4.016115</td>\n",
       "      <td>0.018023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ok</td>\n",
       "      <td>-4.021078</td>\n",
       "      <td>0.017934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>ur</td>\n",
       "      <td>-4.061693</td>\n",
       "      <td>0.017220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>love</td>\n",
       "      <td>-4.098636</td>\n",
       "      <td>0.016595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>day</td>\n",
       "      <td>-4.109447</td>\n",
       "      <td>0.016417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  log_prob_0    prob_0\n",
       "43       go   -3.634024  0.026410\n",
       "41      get   -3.763701  0.023198\n",
       "48       gt   -3.869062  0.020878\n",
       "76       lt   -3.881965  0.020610\n",
       "12     call   -3.935311  0.019540\n",
       "22     come   -4.016115  0.018023\n",
       "99       ok   -4.021078  0.017934\n",
       "152      ur   -4.061693  0.017220\n",
       "75     love   -4.098636  0.016595\n",
       "27      day   -4.109447  0.016417"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.sort_values('log_prob_0', ascending=False)[['feature', 'log_prob_0', 'prob_0']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>log_prob_1</th>\n",
       "      <th>prob_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>call</td>\n",
       "      <td>-2.586027</td>\n",
       "      <td>0.075319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>free</td>\n",
       "      <td>-3.022745</td>\n",
       "      <td>0.048667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>txt</td>\n",
       "      <td>-3.248869</td>\n",
       "      <td>0.038818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>ur</td>\n",
       "      <td>-3.483270</td>\n",
       "      <td>0.030707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>text</td>\n",
       "      <td>-3.635850</td>\n",
       "      <td>0.026362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>mobil</td>\n",
       "      <td>-3.635850</td>\n",
       "      <td>0.026362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>stop</td>\n",
       "      <td>-3.704058</td>\n",
       "      <td>0.024623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>repli</td>\n",
       "      <td>-3.815976</td>\n",
       "      <td>0.022016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>www</td>\n",
       "      <td>-3.815976</td>\n",
       "      <td>0.022016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>claim</td>\n",
       "      <td>-3.842644</td>\n",
       "      <td>0.021437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  log_prob_1    prob_1\n",
       "12     call   -2.586027  0.075319\n",
       "39     free   -3.022745  0.048667\n",
       "150     txt   -3.248869  0.038818\n",
       "152      ur   -3.483270  0.030707\n",
       "139    text   -3.635850  0.026362\n",
       "86    mobil   -3.635850  0.026362\n",
       "134    stop   -3.704058  0.024623\n",
       "114   repli   -3.815976  0.022016\n",
       "170     www   -3.815976  0.022016\n",
       "18    claim   -3.842644  0.021437"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.sort_values('log_prob_1', ascending=False)[['feature', 'log_prob_1', 'prob_1']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrmae을 사용하지 않고 찾는 방법\n",
    "[numpy.argsort](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argsort.html) 사용, 이때 값 구성에 차이가 다소 있음.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: ['go' 'get' 'gt' 'lt' 'call' 'come' 'ok' 'ur' 'love' 'day']\n",
      "Class 1: ['call' 'free' 'txt' 'ur' 'text' 'mobil' 'stop' 'repli' 'www' 'claim']\n"
     ]
    }
   ],
   "source": [
    "print(\"Class 0: {}\".format(X_train.columns.values[np.argsort(clf.feature_log_prob_[0])[-10:][::-1]]))\n",
    "print(\"Class 1: {}\".format(X_train.columns.values[np.argsort(clf.feature_log_prob_[1])[-10:][::-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) 학습된 Multinomial naïve Bayes 모형에서 서로 다른 두 group에 대해서 개별 단어의 $p_i  (i=\\{1,…,175\\})$ 값들의 히스토그램을 그리시오. 이 때 히스토그램을 그리기 위한 막대의 수는 30으로 하시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11380a7f0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1127e4668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.exp(res_df['prob_0']), bins=30)\n",
    "plt.title(\"Word probability distribution: Not Spam(Class 0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x113923be0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1138dd400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.exp(res_df['prob_1']), bins=30)\n",
    "plt.title(\"Word probability distribution: Spam(Class 1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Bernoulli naïve Bayes 모형을 이용해서 세팅 변경 없이 train set으로 학습을 하고 test set을 이용해서 정확도(accuracy), recall, precision, f1 measure 값을 구하시오. (2)의 결과와 비교하여 어느 쪽이 더 나은 모형인지 설명하시오. 이 결과로부터 알 수 있는 사실은 무엇인가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.97675840978593276, 'precision': 0.94247787610619471, 'recall': 0.89495798319327735, 'f1_score': 0.91810344827586199}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "res = dict(\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred),\n",
    "    precision = metrics.precision_score(y_test, y_pred),\n",
    "    recall = metrics.recall_score(y_test, y_pred),\n",
    "    f1_score = metrics.f1_score(y_test, y_pred)\n",
    ")\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
