{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $k$-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# random data generation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "n=50\n",
    "np.random.seed(20)\n",
    "x=np.random.rand(n)-0.5\n",
    "y=np.random.rand(n)-0.5\n",
    "train=pd.DataFrame(data={'x':x,'y':y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 위의 생성한 데이터 중에서 (0,0)의 10 nearest neighbor를 찾으시오. 10 nearest neighbor의 python 기준의 index를 쓰시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088131</td>\n",
       "      <td>0.234301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.397714</td>\n",
       "      <td>-0.091357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.391531</td>\n",
       "      <td>0.278688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.315837</td>\n",
       "      <td>0.303971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.464110</td>\n",
       "      <td>0.286071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y\n",
       "0  0.088131  0.234301\n",
       "1  0.397714 -0.091357\n",
       "2  0.391531  0.278688\n",
       "3  0.315837  0.303971\n",
       "4 -0.464110  0.286071"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['distance'] = np.sqrt(x**2+y**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45, 29, 47, 26,  7,  8, 25,  6,  5, 37])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sort_values('distance').index.values[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 전체 데이터와 (0, 0)에 대한 scatter plot을 그리시오. 이 때 (0,0)은 무작위로 생성한 데이터와 구분되도록 하고, 10 nearest neighbor의 경우에도 nearest neighbor가 아닌 포인트와 구분되도록 scatter plot을 그리시오. (색이나 모양으로 구별)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_knn = train.sort_values('distance').index.values[:10]\n",
    "idx_others = train.sort_values('distance').index.values[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1128bbba8>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111e3a080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(0,0)\n",
    "plt.scatter(x[idx_knn], y[idx_knn])\n",
    "plt.scatter(x[idx_others], y[idx_others])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 기존 데이터에서 y축의 값을 5배한 다음에 다시 (0,0)의 10 nearest neighbor를 찾으시오. 이 때 거리는 유클리디안 거리를 사용하고 10 nearest neighbor의 python 기준의 index를 쓰시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['y_re'] = train['y']*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>distance</th>\n",
       "      <th>y_re</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088131</td>\n",
       "      <td>0.234301</td>\n",
       "      <td>0.250327</td>\n",
       "      <td>1.171503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.397714</td>\n",
       "      <td>-0.091357</td>\n",
       "      <td>0.408071</td>\n",
       "      <td>-0.456783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.391531</td>\n",
       "      <td>0.278688</td>\n",
       "      <td>0.480586</td>\n",
       "      <td>1.393440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.315837</td>\n",
       "      <td>0.303971</td>\n",
       "      <td>0.438351</td>\n",
       "      <td>1.519853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.464110</td>\n",
       "      <td>0.286071</td>\n",
       "      <td>0.545193</td>\n",
       "      <td>1.430357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y  distance      y_re\n",
       "0  0.088131  0.234301  0.250327  1.171503\n",
       "1  0.397714 -0.091357  0.408071 -0.456783\n",
       "2  0.391531  0.278688  0.480586  1.393440\n",
       "3  0.315837  0.303971  0.438351  1.519853\n",
       "4 -0.464110  0.286071  0.545193  1.430357"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['distance_re'] = np.sqrt(x**2+train['y_re']**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>distance</th>\n",
       "      <th>y_re</th>\n",
       "      <th>distance_re</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088131</td>\n",
       "      <td>0.234301</td>\n",
       "      <td>0.250327</td>\n",
       "      <td>1.171503</td>\n",
       "      <td>1.174813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.397714</td>\n",
       "      <td>-0.091357</td>\n",
       "      <td>0.408071</td>\n",
       "      <td>-0.456783</td>\n",
       "      <td>0.605662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.391531</td>\n",
       "      <td>0.278688</td>\n",
       "      <td>0.480586</td>\n",
       "      <td>1.393440</td>\n",
       "      <td>1.447401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.315837</td>\n",
       "      <td>0.303971</td>\n",
       "      <td>0.438351</td>\n",
       "      <td>1.519853</td>\n",
       "      <td>1.552323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.464110</td>\n",
       "      <td>0.286071</td>\n",
       "      <td>0.545193</td>\n",
       "      <td>1.430357</td>\n",
       "      <td>1.503769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y  distance      y_re  distance_re\n",
       "0  0.088131  0.234301  0.250327  1.171503     1.174813\n",
       "1  0.397714 -0.091357  0.408071 -0.456783     0.605662\n",
       "2  0.391531  0.278688  0.480586  1.393440     1.447401\n",
       "3  0.315837  0.303971  0.438351  1.519853     1.552323\n",
       "4 -0.464110  0.286071  0.545193  1.430357     1.503769"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45, 26, 10,  9, 18,  8, 47,  5, 15, 49])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sort_values('distance_re').index.values[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) y축의 값을 5배한 데이터와 (0, 0)에 대한 scatter plot을 그리시오. 이 때 (0,0)은 무작위로 생성한 데이터와 구분되도록 하고, 10 nearest neighbor의 경우에도 nearest neighbor가 아닌 포인트와 구분되도록 scatter plot을 그리시오. (색이나 모양으로 구별) y축의 값을 변경한 후 어떻게 달라졌는지 쓰시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_knn = train.sort_values('distance_re').index.values[:10]\n",
    "idx_others = train.sort_values('distance_re').index.values[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x112922b70>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111d46630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(0,0)\n",
    "plt.scatter(x[idx_knn], train['y_re'][idx_knn])\n",
    "plt.scatter(x[idx_others], train['y_re'][idx_others])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) decision tree를 학습하는 단계에서 overfitting을 막기 위해서 여러 parameter를 이용하는데 어떤 조합이 가장 좋은지 stratified k-fold cross-validation을 이용해서 알아보고자 한다.  변경하고자 하는 옵션은 max_depth, min_samples_split, min_samples_leaf 이고 사용하게 될 값은 다음과 같다. \n",
    "- max_depth=[3, 4]\n",
    "- min_samples_split=[100, 200, 300]\n",
    "- min_samples_leaf=[50, 100]\n",
    "\n",
    "### 위의 세 옵션에 대해서 5-fold cross-validation을 정확도를 기준으로 수행한다고 했을 때 아래 표에 각 validation step마다 validation set에 의한 정확도를 채우시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail   ...    char_freq_;  char_freq_(  \\\n",
       "0             0.00            0.00   ...           0.00        0.000   \n",
       "1             0.00            0.94   ...           0.00        0.132   \n",
       "2             0.64            0.25   ...           0.01        0.143   \n",
       "3             0.31            0.63   ...           0.00        0.137   \n",
       "4             0.31            0.63   ...           0.00        0.135   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778        0.000        0.000   \n",
       "1          0.0        0.372        0.180        0.048   \n",
       "2          0.0        0.276        0.184        0.010   \n",
       "3          0.0        0.137        0.000        0.000   \n",
       "4          0.0        0.135        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  target  \n",
       "0                       278       1  \n",
       "1                      1028       1  \n",
       "2                      2259       1  \n",
       "3                       191       1  \n",
       "4                       191       1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_table(\"./spambase.txt\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colnames = list(data.columns.values)[:-1]\n",
    "X = data[colnames]\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "idx_train, idx_test = [], []\n",
    "for train, test in skf.split(X, y) :\n",
    "    idx_train.append(train)\n",
    "    idx_test.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'max_depth': 3, 'min_samples_leaf': 50, 'min_samples_split': 100},\n",
       " {'max_depth': 3, 'min_samples_leaf': 100, 'min_samples_split': 100},\n",
       " {'max_depth': 3, 'min_samples_leaf': 50, 'min_samples_split': 200},\n",
       " {'max_depth': 3, 'min_samples_leaf': 100, 'min_samples_split': 200},\n",
       " {'max_depth': 3, 'min_samples_leaf': 50, 'min_samples_split': 300},\n",
       " {'max_depth': 3, 'min_samples_leaf': 100, 'min_samples_split': 300},\n",
       " {'max_depth': 4, 'min_samples_leaf': 50, 'min_samples_split': 100},\n",
       " {'max_depth': 4, 'min_samples_leaf': 100, 'min_samples_split': 100},\n",
       " {'max_depth': 4, 'min_samples_leaf': 50, 'min_samples_split': 200},\n",
       " {'max_depth': 4, 'min_samples_leaf': 100, 'min_samples_split': 200},\n",
       " {'max_depth': 4, 'min_samples_leaf': 50, 'min_samples_split': 300},\n",
       " {'max_depth': 4, 'min_samples_leaf': 100, 'min_samples_split': 300}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth=[3, 4]\n",
    "min_samples_split=[100, 200, 300]\n",
    "min_samples_leaf=[50, 100]\n",
    "params = [dict(max_depth=d, min_samples_split=s, min_samples_leaf=l) \n",
    "          for d in max_depth for s in min_samples_split for l in min_samples_leaf]\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'min_samples_split': 100, 'min_samples_leaf': 50} 0.865237080857\n",
      "{'max_depth': 3, 'min_samples_split': 100, 'min_samples_leaf': 100} 0.857414292786\n",
      "{'max_depth': 3, 'min_samples_split': 200, 'min_samples_leaf': 50} 0.865237080857\n",
      "{'max_depth': 3, 'min_samples_split': 200, 'min_samples_leaf': 100} 0.857414292786\n",
      "{'max_depth': 3, 'min_samples_split': 300, 'min_samples_leaf': 50} 0.865237080857\n",
      "{'max_depth': 3, 'min_samples_split': 300, 'min_samples_leaf': 100} 0.854156963796\n",
      "{'max_depth': 4, 'min_samples_split': 100, 'min_samples_leaf': 50} 0.878262616095\n",
      "{'max_depth': 4, 'min_samples_split': 100, 'min_samples_leaf': 100} 0.861517085913\n",
      "{'max_depth': 4, 'min_samples_split': 200, 'min_samples_leaf': 50} 0.880438894658\n",
      "{'max_depth': 4, 'min_samples_split': 200, 'min_samples_leaf': 100} 0.861517085913\n",
      "{'max_depth': 4, 'min_samples_split': 300, 'min_samples_leaf': 50} 0.880003638946\n",
      "{'max_depth': 4, 'min_samples_split': 300, 'min_samples_leaf': 100} 0.868923521885\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "result_acc = []\n",
    "result_kfold = []\n",
    "for p in params :\n",
    "    clf = DecisionTreeClassifier(\n",
    "                            max_depth = p['max_depth'], \n",
    "                            min_samples_leaf = p['min_samples_leaf'],\n",
    "                            min_samples_split = p['min_samples_split']\n",
    "    )\n",
    "    tmp_acc = []\n",
    "    for k in range(len(idx_train)) :\n",
    "        clf.fit(X.iloc[idx_train[k]], y[idx_train[k]])\n",
    "        tmp_acc.append(clf.score(X.iloc[idx_test[k]], y[idx_test[k]]))\n",
    "    result_acc.append([p['max_depth'], p['min_samples_split'], p['min_samples_leaf']]+tmp_acc)\n",
    "    res = np.array(tmp_acc).mean()\n",
    "    result_kfold.append([p['max_depth'], p['min_samples_split'], p['min_samples_leaf'], res])\n",
    "    print(p, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>Fold1</th>\n",
       "      <th>Fold2</th>\n",
       "      <th>Fold3</th>\n",
       "      <th>Fold4</th>\n",
       "      <th>Fold5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.850163</td>\n",
       "      <td>0.879479</td>\n",
       "      <td>0.888165</td>\n",
       "      <td>0.914037</td>\n",
       "      <td>0.794342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.836048</td>\n",
       "      <td>0.874050</td>\n",
       "      <td>0.880565</td>\n",
       "      <td>0.902067</td>\n",
       "      <td>0.794342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>0.850163</td>\n",
       "      <td>0.879479</td>\n",
       "      <td>0.888165</td>\n",
       "      <td>0.914037</td>\n",
       "      <td>0.794342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>0.836048</td>\n",
       "      <td>0.874050</td>\n",
       "      <td>0.880565</td>\n",
       "      <td>0.902067</td>\n",
       "      <td>0.794342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>0.850163</td>\n",
       "      <td>0.879479</td>\n",
       "      <td>0.888165</td>\n",
       "      <td>0.914037</td>\n",
       "      <td>0.794342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>0.825190</td>\n",
       "      <td>0.868621</td>\n",
       "      <td>0.880565</td>\n",
       "      <td>0.902067</td>\n",
       "      <td>0.794342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.892508</td>\n",
       "      <td>0.895765</td>\n",
       "      <td>0.903366</td>\n",
       "      <td>0.898803</td>\n",
       "      <td>0.800871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.878393</td>\n",
       "      <td>0.890337</td>\n",
       "      <td>0.895765</td>\n",
       "      <td>0.894450</td>\n",
       "      <td>0.748640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>0.892508</td>\n",
       "      <td>0.895765</td>\n",
       "      <td>0.903366</td>\n",
       "      <td>0.906420</td>\n",
       "      <td>0.804135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>0.878393</td>\n",
       "      <td>0.890337</td>\n",
       "      <td>0.895765</td>\n",
       "      <td>0.894450</td>\n",
       "      <td>0.748640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>0.892508</td>\n",
       "      <td>0.895765</td>\n",
       "      <td>0.903366</td>\n",
       "      <td>0.914037</td>\n",
       "      <td>0.794342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>0.867535</td>\n",
       "      <td>0.884908</td>\n",
       "      <td>0.895765</td>\n",
       "      <td>0.902067</td>\n",
       "      <td>0.794342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_samples_split  min_samples_leaf     Fold1     Fold2  \\\n",
       "0           3                100                50  0.850163  0.879479   \n",
       "1           3                100               100  0.836048  0.874050   \n",
       "2           3                200                50  0.850163  0.879479   \n",
       "3           3                200               100  0.836048  0.874050   \n",
       "4           3                300                50  0.850163  0.879479   \n",
       "5           3                300               100  0.825190  0.868621   \n",
       "6           4                100                50  0.892508  0.895765   \n",
       "7           4                100               100  0.878393  0.890337   \n",
       "8           4                200                50  0.892508  0.895765   \n",
       "9           4                200               100  0.878393  0.890337   \n",
       "10          4                300                50  0.892508  0.895765   \n",
       "11          4                300               100  0.867535  0.884908   \n",
       "\n",
       "       Fold3     Fold4     Fold5  \n",
       "0   0.888165  0.914037  0.794342  \n",
       "1   0.880565  0.902067  0.794342  \n",
       "2   0.888165  0.914037  0.794342  \n",
       "3   0.880565  0.902067  0.794342  \n",
       "4   0.888165  0.914037  0.794342  \n",
       "5   0.880565  0.902067  0.794342  \n",
       "6   0.903366  0.898803  0.800871  \n",
       "7   0.895765  0.894450  0.748640  \n",
       "8   0.903366  0.906420  0.804135  \n",
       "9   0.895765  0.894450  0.748640  \n",
       "10  0.903366  0.914037  0.794342  \n",
       "11  0.895765  0.902067  0.794342  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame as df\n",
    "colnames = ['max_depth', 'min_samples_split', 'min_samples_leaf', 'Fold1', 'Fold2', 'Fold3', 'Fold4', 'Fold5']\n",
    "result_acc = df(result_acc, columns=colnames)\n",
    "result_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>Acc_Fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.865237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.857414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>0.865237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>0.857414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>0.865237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>0.854157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.878263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.861517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>0.880439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>0.861517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>0.880004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>0.868924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_samples_split  min_samples_leaf  Acc_Fold\n",
       "0           3                100                50  0.865237\n",
       "1           3                100               100  0.857414\n",
       "2           3                200                50  0.865237\n",
       "3           3                200               100  0.857414\n",
       "4           3                300                50  0.865237\n",
       "5           3                300               100  0.854157\n",
       "6           4                100                50  0.878263\n",
       "7           4                100               100  0.861517\n",
       "8           4                200                50  0.880439\n",
       "9           4                200               100  0.861517\n",
       "10          4                300                50  0.880004\n",
       "11          4                300               100  0.868924"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames= colnames[:3] + ['Acc_Fold']\n",
    "result_kfold = df(result_kfold, columns=colnames)\n",
    "result_kfold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 평균적으로 가장 정확도가 높은 조건으로 전체 데이터를 이용해서 decision tree를 학습하고 그 결과 tree를 그리시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>Acc_Fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>0.880439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  min_samples_split  min_samples_leaf  Acc_Fold\n",
       "8          4                200                50  0.880439"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = result_kfold[result_kfold['Acc_Fold']==np.max(result_kfold['Acc_Fold'])]\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4, 'min_samples_leaf': 50, 'min_samples_split': 200}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_param = params[res_df.index.values[0]]\n",
    "res_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=50,\n",
       "            min_samples_split=200, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(\n",
    "                            max_depth = res_param['max_depth'], \n",
    "                            min_samples_leaf = res_param['min_samples_leaf'],\n",
    "                            min_samples_split = res_param['min_samples_split']\n",
    "    )\n",
    "clf.fit(X,y)\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) sklearn.model_selection.train_test_split을 이용해서 데이터를 train set과 test set (validation set)으로 나누고자 한다. 먼저 주어진 데이터를 불러와 input에 해당하는 X와 output 값만 담고 있는 y 변수를 생성하고 여기서부터 train_test_split를 이용해서 Xtrain, Xtest, ytrain, ytest를 얻으시오. 이 때 test_size=0.2, stratify=y, random_state=150으로 설정하시오. Xtrain에 들어있는 데이터 중 맨 위에 있는 5개 데이터와 Xtest에 들어있는 데이터 중 맨 위에 있는 5개 데이터를 jupyter notebook 화면에 print하시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Multinomial naïve Bayes 모형을 이용해서 세팅이 변경없이 train set으로 학습을 하고 test set을 이용해서 정확도(accuracy), recall, precision, f1 measure 값을 구하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 학습된 Multinomial naïve Bayes 모형으로부터 서로 다른 두 group(스팸 SMS와 스팸이 아닌 SMS)일 확률을 높이는데 가장 기여를 많이 하는 단어 상위 10개씩을 찾으시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) 학습된 Multinomial naïve Bayes 모형에서 서로 다른 두 group에 대해서 개별 단어의 $p_i  (i=\\{1,…,175\\})$ 값들의 히스토그램을 그리시오. 이 때 히스토그램을 그리기 위한 막대의 수는 30으로 하시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Bernoulli naïve Bayes 모형을 이용해서 세팅 변경 없이 train set으로 학습을 하고 test set을 이용해서 정확도(accuracy), recall, precision, f1 measure 값을 구하시오. (2)의 결과와 비교하여 어느 쪽이 더 나은 모형인지 설명하시오. 이 결과로부터 알 수 있는 사실은 무엇인가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
