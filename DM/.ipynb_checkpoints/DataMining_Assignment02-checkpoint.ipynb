{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $k$-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# random data generation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "n=50\n",
    "np.random.seed(20)\n",
    "x=np.random.rand(n)-0.5\n",
    "y=np.random.rand(n)-0.5\n",
    "train=pd.DataFrame(data={'x':x,'y':y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 위의 생성한 데이터 중에서 (0,0)의 10 nearest neighbor를 찾으시오. 10 nearest neighbor의 python 기준의 index를 쓰시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088131</td>\n",
       "      <td>0.234301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.397714</td>\n",
       "      <td>-0.091357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.391531</td>\n",
       "      <td>0.278688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.315837</td>\n",
       "      <td>0.303971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.464110</td>\n",
       "      <td>0.286071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y\n",
       "0  0.088131  0.234301\n",
       "1  0.397714 -0.091357\n",
       "2  0.391531  0.278688\n",
       "3  0.315837  0.303971\n",
       "4 -0.464110  0.286071"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['distance'] = np.sqrt(x**2+y**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45, 29, 47, 26,  7,  8, 25,  6,  5, 37])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sort_values('distance').index.values[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 전체 데이터와 (0, 0)에 대한 scatter plot을 그리시오. 이 때 (0,0)은 무작위로 생성한 데이터와 구분되도록 하고, 10 nearest neighbor의 경우에도 nearest neighbor가 아닌 포인트와 구분되도록 scatter plot을 그리시오. (색이나 모양으로 구별)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_knn = train.sort_values('distance').index.values[:10]\n",
    "idx_others = train.sort_values('distance').index.values[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1128bbba8>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFmBJREFUeJzt3X+IXWedx/HPZ2dTE0bbVBs6t/mxaSAI4o4Yxirpyqpt\nxzajpkIodbV2FyEUtzrCok0RytD9w7qC2yn4g6wKERdKiKWNTqXRqOASKp2kktKW2jCLNOnE1q5G\nySZrU7/7x72TTiZ35t4759zz8/2CMHPPPJnzzJk753ue7/PLESEAQP38Vd4VAADkgwAAADVFAACA\nmiIAAEBNEQAAoKYIAABQUwQAAKgpAgAA1BQBAABq6q/zrsBSrrjiiti4cWPe1QCA0jh8+PDvImJN\nN2ULHQA2btyo6enpvKsBAKVh+zfdliUFBAA1RQAAgJoiAABATREAAKCmCAAAUFMEAACoKQIAANQU\nAQAACmBqZkqj+0Y1vGdYo/tGNTUz1fdzFnoiGADUwdTMlCYOTejsa2clSbOnZzVxaEKSNLZprG/n\npQUAADmbPDJ5/uY/5+xrZzV5ZLKv5yUAAEDOTp4+2dPxtBAAcpJHvg9AMQ0NDvV0PC0EgBzM5ftm\nT88qFOfzfQQBoJ7Gt4xr5cDKC46tHFip8S3jfT0vASAHeeX7skQLB+je2KYxTWydUGOwIctqDDY0\nsXWirx3AEqOAcpFXvi8reY1oAMpsbNNY5n8ftABykFe+Lyt1aOEAVZBKALB9o+3nbB+zvWuJcu+y\nfc72jjTOW1Z55fuyUvUWDlAViVNAtgckfU3SDZKOS3rC9v6IeKZNuS9LOpD0nGU318ybPDKpk6dP\namhwSONbxiuTHhkaHNLs6dm2xwEURxp9ANdIOhYRM5Jk+0FJ2yU9s6DcZyR9X9K7Ujhn6eWR75tv\namaqbwFofMv4BX0AUrVaOP3Sz98J0E4aAWCtpBfmvT4u6d3zC9heK+mjkt6vDgHA9k5JOyVpw4YN\nKVQPC/W7k7bqLZx+oOMcechqFND9ku6KiL/YXrJgROyWtFuSRkZGIoO61c5SnbRp3WzybuGUTRa/\nE2ChNALACUnr571e1zo234ikB1s3/yskbbN9LiIeTuH8lZJFGoBO2uLhd4I8pDEK6AlJm21fbfsS\nSbdK2j+/QERcHREbI2KjpH2SPs3N/2JZzRCu+jDUMuJ3gjwkDgARcU7SnZIek/SspL0R8bTtO2zf\nkfT710lW4+erPgy1jPidIA+p9AFExKOSHl1w7JuLlP3HNM5ZRVmlAeikLR5+J8gDS0EUSJbj5+mk\nLR5+J8gaS0EUCGkAAFmiBVAgpAEAZIkAUDCkAQBkhRQQkDP2TkBeaAEAOWIJCOSJFgCQI/ZOQJ4I\nAECOWAICeSIAADliCQjkiQAA5Ii5H8gTncBAjpj7gTwRAICcMfcDeSEFBKCSmF/RGS0AAJXD/Iru\n0AIAUDnMr+gOAQBA5TC/ojuVDADk/oB6Y35FdyoXALLaVxdANpbzQJfV/IqyP2xWLgCQ+wOqY7kP\ndGObxjSxdUKNwYYsa/UbVusNA2/Q3b+4O7UbdRUeNisXAMj9AdWR5IFubNOYDuw4oC+990s6e+6s\nTv35VKo36io8bFYuAJD7A6ojjQe6ft2oq/CwWbkAwNoqQHWk8UDXrxt1FR42KxcAFub+GoMNTWyd\nYPIHaqnsnZRpPND160ZdhYfNSs4EZm0VoBqzYdNYLG98y/gF10FK50ZdhYX8HBF512FRIyMjMT09\nnXc1gFIa3Teq2dOzFx1vDDZ0YMeBHGqUn6mZqVLfqHth+3BEjHRTtpItAADV6KRMC1mB9irXBwCg\nqQqdlOgvAgBQEr126FahkxL9RQoIKIHldOhWoZMS/UUnMFACdOiiW710ApMCAkqADl30AwEAKAE6\ndNEPBACgBOjQbSr7zOaiSSUA2L7R9nO2j9ne1ebrH7d91PZTtg/Zfkca5wUyd3Sv9O9vlyZWNz8e\n3ZvJaVnipBrLLxdN4k5g2wOSfi3pBknHJT0h6WMR8cy8MlslPRsRv7d9k6SJiHh3p+9NJzAK5ehe\n6QeflV498/qxFaukDz8gDd+SX71qgo7w7mTdCXyNpGMRMRMRf5b0oKTt8wtExKGI+H3r5eOS1qVw\nXiBbB++98OYvNV8fvDef+qSgTCkVOsLTl0YAWCvphXmvj7eOLeZTkn6UwnmBbJ063tvxgitbSoWO\n8PRl2gls+/1qBoC7liiz0/a07emXX345u8oBnVy2SMN1seMFV7YdregIT18aAeCEpPXzXq9rHbuA\n7WFJ35K0PSJeWeybRcTuiBiJiJE1a9akUD0gJdfd08z5z7diVfN4CZUtpUJHePrSWAriCUmbbV+t\n5o3/Vkn/ML+A7Q2SHpJ0W0T8OoVzAtmb6+g9eG8z7XPZuubNv6QdwEODQ207VYucUmFVz3QlDgAR\ncc72nZIekzQg6TsR8bTtO1pf/6akeyS9RdLXbUvSuW57qYFCGb6ltDf8hfq1UQrKg7WAgBqr00Yp\ndcGGMCi/o3srk2opMlIq9UYAQPEsnHB16oXma4kggNTQ+mEtIBRRBSdcoVjKNgeiXwgAKJ6KTbhC\n8ZRtDkS/EABQPGWecJXTYnHoTdnmQPQLAQDFU9YJV3N9F6dekBSv910QBAqHZSWaCAAonuFbmits\nXrZekpsfy7DiJn0XpcGyEk2MAkIxlXHCFX0XpTE32qfdKKA6jQ4iAABpuWxdK/3T5jgKp90ciLnR\nQXMdxHOjg+bKVw0pICAtZe27wPl9EXb9YletRgfRAgDSUrHF4upi4VN/O1UdHUQAANJUxr6Lmms3\nJ2Chqo4OIgUELAfj/Suj09N9lUcH0QIAesVaRZWy2L4IUnPD+SqPAqIFAPSK8f6VsticgPvee58O\n7DhQ2Zu/RAsA6B3j/Su1XPdScwKqjgAA9Kru4/0rmAKr674IpICAXtV9vD8psMogAAC9KspaRXmN\nRCIFVhmkgIDlyHu8f55pmLqnwCqEFgBQRnmmYeqeAqsQAgBQRnmmYYqSAkNipICAMso7DZN3Cgyp\noAVQcXOrHA7vGdbovtHabXpdWaRhkAJaABVWt7XNa4WVR5ECR0TedVjUyMhITE9P512N0hrdN9p2\njZPGYEMHdhzIoUYA+s324YgY6aYsKaAKW2yVw6qubQ6gNwSACltsDfOqrm0OoDcEgApbbJXDqq5t\nDqA3dAJXWJ1XOcQCFVq9E+khAFRcXVc5xDwVXL0T6SAFBFQdq3diEQSAEmAyFxKt/MnqnVgEKaCC\nYzIXEqdw8l42AoWVSgvA9o22n7N9zPauNl+37QdaXz9qe0sa562DySOT52/+c86+dlaTRyZzqhEy\nlzSFw7IRWETiFoDtAUlfk3SDpOOSnrC9PyKemVfsJkmbW//eLekbrY/oIMvJXFMzU4wY6tLDT57Q\nVx57Ti/+4YyuWr1Kn//gW3XzO9f252RJUzgsG4FFpJECukbSsYiYkSTbD0raLml+ANgu6bvRXHfi\ncdurbTci4uJ1CnCBocGhtss5pD2Zi1RT9x5+8oTufugpnXn1NUnSiT+c0d0PPSVJ/QkCaaRwWL0T\nbaSRAloraf6783jrWK9l0EZWk7lINXXvK489d/7mP+fMq6/pK489158TksJBnxSuE9j2Tkk7JWnD\nhg051yZ/WU3mYt2g7r34hzM9HU+MFA76JI0AcELS+nmv17WO9VpGkhQRuyXtlpqrgaZQv9LLYjJX\nVqmmKrhq9SqdaHOzv2r1qjalU0IKB32QRgroCUmbbV9t+xJJt0rav6DMfkmfbI0Geo+kU+T/i4V1\ng7r3+Q++VatWDFxwbNWKAX3+g2/NqUbA8iRuAUTEOdt3SnpM0oCk70TE07bvaH39m5IelbRN0jFJ\n/yvpn5KeF+li3aDuzXX0ZjYKCOgTNoQBgAphQxgAQEeVDACsnQMAnRVuGGhSTGgCgO5UrgXAhCYA\n6E7lAgATmgCgO5ULAGyEDgDdqVwAYEITAHSncp3ATGgCgO5ULgBIbIQOLMvRvSw4VzOVDABFx8Yr\nKJyk206ilCrXB1B0c/MUZk/PKhTn5ykwWQ25SrrtJEqJAJAx5imgkJJuO4lSIgBkjHkKKKTFtpfs\nZdvJGivr8jMEgIwxTwGFxLaTy1bmtC4BIGPMU0AhDd8iffgB6bL1ktz8+OEH6ADuQpnTuowCyhjz\nFFBYbDu5LGVO6xIAcsA8BaA6yryfNikgAEigzGldWgAJMakLqLcyp3UJAAmw+QwAqbxpXVJACZS5\n9x8ACAAJlLn3HwAIAAkwqQtAmREAEihz7z8A0AmcQJl7/wGAAJBQWXv/gTJgmHV/EQAAFBLDrPuP\nPgAAhcQw6/4jAAAoJIZZ9x8BAEAhXXrJpT0dR+8IAAAKyXZPx9E7AgCAQjr1f6d6Oo7eEQAAFBIz\n7fuPAACgkJhp33+JAoDtN9v+se3nWx8vb1Nmve2f2X7G9tO2+e0B6Ghs05gmtk6oMdiQZTUGG5rY\nOsEcgBQ5Ipb/n+1/k/Q/EXGf7V2SLo+IuxaUaUhqRMQR22+SdFjSzRHxTKfvPzIyEtPT08uuH7rH\njEugGmwfjoiRbsomTQFtl7Sn9fkeSTcvLBARsxFxpPX5nyQ9K2ltwvMiRXMzLmdPzyoU52dcTs1M\n5V01AH2UNABcGRFzuyGflHTlUoVtb5T0Tkm/THhepIgZl8jT1MyURveNanjPsEb3jfLgkaGOawHZ\n/omkdt3uX5z/IiLC9qL5JNtvlPR9SZ+LiD8uUW6npJ2StGHDhk7VQwqYcZmCo3ulg/dKp45Ll62T\nrrtHGr4l71oVHuv95KtjCyAiro+It7f594ik37Zy/HO5/pfafQ/bK9S8+f9nRDzU4Xy7I2IkIkbW\nrFnT+0+EnjHcLqGje6UffFY69YKkaH78wWebx7EkWp/5SpoC2i/p9tbnt0t6ZGEBN6ftfVvSsxHx\n1YTnQx8w3C6hg/dKr5658NirZ5rHsSRan/lKGgDuk3SD7eclXd96LdtX2X60VeZaSbdJ+oDtX7X+\nbUt4XqSI4XYJnTre23GcR+szX4n2A4iIVyRd1+b4i5K2tT7/L0ks3lFwdd7YJvEQ2MvWtdI/bY5j\nSeNbxi/oA5BofWaJmcCotVSGwF53j7Ri1YXHVqxqHseSaH3mK9FEsH5jIhj6bXTfqGZPz150vDHY\n0IEdB7r/RowCQkH0MhGMLSFRa6l1Qg7fwg0fpUMKCLVGJyTqjACAWmMILOqMFBBqba6zkYXwUEcE\nANRenYfAot5IAQFATREAAKCmCAAAUFMEAACoKQIAANQUAQAAaooAAAA1RQAAgJoiAABATREAAKCm\nCAAAUFMEAACoKQIAANQUAQAAaqrWAWBqZkqj+0Y1vGdYo/tGe9sIHLXAewRVVtv9AKZmpjRxaEJn\nXzsrSZo9PauJQxOSxNrwkMR7BNVX2xbA5JHJ83/Yc86+dlaTRyZzqhGKhvcIqq62AeDk6ZM9HUf9\n8B5B1dU2AAwNDvV0HPXDewRVV9sAML5lXCsHVl5wbOXASo1vGc+pRiga3iOoutp2As914k0emdTJ\n0yc1NDik8S3jdO7hPN4jqDpHRN51WNTIyEhMT0/nXQ0AKA3bhyNipJuytU0BAUDdEQBQKkzMAtJT\n2z4ApGNqZiqzHDkTs4B00QLAss3dkGdPzyoU52/I/XoqZ2IWkC4CQM0lSalkfUNmYhaQrkQBwPab\nbf/Y9vOtj5cvUXbA9pO2f5jknEhP0if4rG/ITMwC0pW0BbBL0sGI2CzpYOv1YsYlPZvwfEhR0if4\nrG/ITMwC0pU0AGyXtKf1+R5JN7crZHudpDFJ30p4PqQo6RN81jfksU1jmtg6ocZgQ5bVGGxoYusE\nHcDAMiUdBXRlRMy2Pj8p6cpFyt0v6QuS3pTwfEjR0OCQZk/Ptj3ejTxmyo5tGuOGD6SkYwCw/RNJ\n7e4IX5z/IiLC9kXTim1/SNJLEXHY9vu6ON9OSTslacOGDZ2KYxnmhm62u/n3+gTPDRkor44BICKu\nX+xrtn9ruxERs7Ybkl5qU+xaSR+xvU3SSkmX2v5eRHxikfPtlrRbai4F0c0Pge4tHEs/X2OwwVo3\nQI0k7QPYL+n21ue3S3pkYYGIuDsi1kXERkm3SvrpYjd/9F+7jl+pefM/sOMAN3+gRpIGgPsk3WD7\neUnXt17L9lW2H01aOaSPsfQA5iTqBI6IVyRd1+b4i5K2tTn+c0k/T3JOJJO04xdAdTATuGYYSw9g\nDovB1QybnACYQwCoIYZuApBIAQHoAvswVBMtAABLYh+G6qIFAGBJy100kFZD8dECQCqy3BkM2VrO\n3BFaDeVACwCJZb0zGLK1nGW/2b2tHAgASIw/9mpbztwRZpyXAykgJMYfe7UtZ+4IM87LgQCAxPhj\nr75e546Mbxm/aNVZZpwXDykgJMbyEliI3dvKgRYAEmN5CbTDjPPiIwAgFfyxA+VDCggAaooAAAA1\nRQAAgJoiAABATREAAKCmCAAAUFOOiLzrsCjbL0v6Td71WOAKSb/LuxIFwHVo4jq8jmvRlPd1+JuI\nWNNNwUIHgCKyPR0RI3nXI29chyauw+u4Fk1lug6kgACgpggAAFBTBIDe7c67AgXBdWjiOryOa9FU\nmutAHwAA1BQtAACoKQJAB7bfbPvHtp9vfbx8ibIDtp+0/cMs65iFbq6D7fW2f2b7GdtP267MhgC2\nb7T9nO1jtne1+bptP9D6+lHbW/KoZ791cR0+3vr5n7J9yPY78qhnv3W6DvPKvcv2Ods7sqxftwgA\nne2SdDAiNks62Hq9mHFJz2ZSq+x1cx3OSfqXiHibpPdI+mfbb8uwjn1he0DS1yTdJOltkj7W5ue6\nSdLm1r+dkr6RaSUz0OV1+G9Jfx8RfyvpX1WifHi3urwOc+W+LOlAtjXsHgGgs+2S9rQ+3yPp5naF\nbK+TNCbpWxnVK2sdr0NEzEbEkdbnf1IzGK7NrIb9c42kYxExExF/lvSgmtdjvu2SvhtNj0tabbuR\ndUX7rON1iIhDEfH71svHJa3LuI5Z6Ob9IEmfkfR9SS9lWbleEAA6uzIi5ja8PSnpykXK3S/pC5L+\nkkmtstftdZAk2d4o6Z2SftnfamViraQX5r0+rosDWzdlyq7Xn/FTkn7U1xrlo+N1sL1W0kdV8JYg\nO4JJsv0TSe12MP/i/BcREbYvGjZl+0OSXoqIw7bf159a9l/S6zDv+7xRzSefz0XEH9OtJcrA9vvV\nDAB/l3ddcnK/pLsi4i+2867LoggAkiLi+sW+Zvu3thsRMdtq0rdrzl0r6SO2t0laKelS29+LiE/0\nqcp9kcJ1kO0Vat78/zMiHupTVbN2QtL6ea/XtY71WqbsuvoZbQ+rmQq9KSJeyahuWermOoxIerB1\n879C0jbb5yLi4Wyq2B1SQJ3tl3R76/PbJT2ysEBE3B0R6yJio6RbJf20bDf/LnS8Dm6+278t6dmI\n+GqGdeu3JyRttn217UvU/B3vX1Bmv6RPtkYDvUfSqXkps6roeB1sb5D0kKTbIuLXOdQxCx2vQ0Rc\nHREbW/eEfZI+XbSbv0QA6MZ9km6w/byk61uvZfsq24/mWrNsdXMdrpV0m6QP2P5V69+2fKqbnog4\nJ+lOSY+p2bG9NyKetn2H7TtaxR6VNCPpmKT/kPTpXCrbR11eh3skvUXS11u//+mcqts3XV6HUmAm\nMADUFC0AAKgpAgAA1BQBAABqigAAADVFAACAmiIAAEBNEQAAoKYIAABQU/8PDNxjq3F1594AAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111e3a080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(0,0)\n",
    "plt.scatter(x[idx_knn], y[idx_knn])\n",
    "plt.scatter(x[idx_others], y[idx_others])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 기존 데이터에서 y축의 값을 5배한 다음에 다시 (0,0)의 10 nearest neighbor를 찾으시오. 이 때 거리는 유클리디안 거리를 사용하고 10 nearest neighbor의 python 기준의 index를 쓰시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['y_re'] = train['y']*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>distance</th>\n",
       "      <th>y_re</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088131</td>\n",
       "      <td>0.234301</td>\n",
       "      <td>0.250327</td>\n",
       "      <td>1.171503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.397714</td>\n",
       "      <td>-0.091357</td>\n",
       "      <td>0.408071</td>\n",
       "      <td>-0.456783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.391531</td>\n",
       "      <td>0.278688</td>\n",
       "      <td>0.480586</td>\n",
       "      <td>1.393440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.315837</td>\n",
       "      <td>0.303971</td>\n",
       "      <td>0.438351</td>\n",
       "      <td>1.519853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.464110</td>\n",
       "      <td>0.286071</td>\n",
       "      <td>0.545193</td>\n",
       "      <td>1.430357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y  distance      y_re\n",
       "0  0.088131  0.234301  0.250327  1.171503\n",
       "1  0.397714 -0.091357  0.408071 -0.456783\n",
       "2  0.391531  0.278688  0.480586  1.393440\n",
       "3  0.315837  0.303971  0.438351  1.519853\n",
       "4 -0.464110  0.286071  0.545193  1.430357"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['distance_re'] = np.sqrt(x**2+train['y_re']**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>distance</th>\n",
       "      <th>y_re</th>\n",
       "      <th>distance_re</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088131</td>\n",
       "      <td>0.234301</td>\n",
       "      <td>0.250327</td>\n",
       "      <td>1.171503</td>\n",
       "      <td>1.174813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.397714</td>\n",
       "      <td>-0.091357</td>\n",
       "      <td>0.408071</td>\n",
       "      <td>-0.456783</td>\n",
       "      <td>0.605662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.391531</td>\n",
       "      <td>0.278688</td>\n",
       "      <td>0.480586</td>\n",
       "      <td>1.393440</td>\n",
       "      <td>1.447401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.315837</td>\n",
       "      <td>0.303971</td>\n",
       "      <td>0.438351</td>\n",
       "      <td>1.519853</td>\n",
       "      <td>1.552323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.464110</td>\n",
       "      <td>0.286071</td>\n",
       "      <td>0.545193</td>\n",
       "      <td>1.430357</td>\n",
       "      <td>1.503769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y  distance      y_re  distance_re\n",
       "0  0.088131  0.234301  0.250327  1.171503     1.174813\n",
       "1  0.397714 -0.091357  0.408071 -0.456783     0.605662\n",
       "2  0.391531  0.278688  0.480586  1.393440     1.447401\n",
       "3  0.315837  0.303971  0.438351  1.519853     1.552323\n",
       "4 -0.464110  0.286071  0.545193  1.430357     1.503769"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45, 26, 10,  9, 18,  8, 47,  5, 15, 49])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sort_values('distance_re').index.values[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) y축의 값을 5배한 데이터와 (0, 0)에 대한 scatter plot을 그리시오. 이 때 (0,0)은 무작위로 생성한 데이터와 구분되도록 하고, 10 nearest neighbor의 경우에도 nearest neighbor가 아닌 포인트와 구분되도록 scatter plot을 그리시오. (색이나 모양으로 구별) y축의 값을 변경한 후 어떻게 달라졌는지 쓰시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_knn = train.sort_values('distance_re').index.values[:10]\n",
    "idx_others = train.sort_values('distance_re').index.values[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x112922b70>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111d46630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(0,0)\n",
    "plt.scatter(x[idx_knn], train['y_re'][idx_knn])\n",
    "plt.scatter(x[idx_others], train['y_re'][idx_others])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) decision tree를 학습하는 단계에서 overfitting을 막기 위해서 여러 parameter를 이용하는데 어떤 조합이 가장 좋은지 stratified k-fold cross-validation을 이용해서 알아보고자 한다.  변경하고자 하는 옵션은 max_depth, min_samples_split, min_samples_leaf 이고 사용하게 될 값은 다음과 같다. \n",
    "- max_depth=[3, 4]\n",
    "- min_samples_split=[100, 200, 300]\n",
    "- min_samples_leaf=[50, 100]\n",
    "\n",
    "### 위의 세 옵션에 대해서 5-fold cross-validation을 정확도를 기준으로 수행한다고 했을 때 아래 표에 각 validation step마다 validation set에 의한 정확도를 채우시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail   ...    char_freq_;  char_freq_(  \\\n",
       "0             0.00            0.00   ...           0.00        0.000   \n",
       "1             0.00            0.94   ...           0.00        0.132   \n",
       "2             0.64            0.25   ...           0.01        0.143   \n",
       "3             0.31            0.63   ...           0.00        0.137   \n",
       "4             0.31            0.63   ...           0.00        0.135   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778        0.000        0.000   \n",
       "1          0.0        0.372        0.180        0.048   \n",
       "2          0.0        0.276        0.184        0.010   \n",
       "3          0.0        0.137        0.000        0.000   \n",
       "4          0.0        0.135        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  target  \n",
       "0                       278       1  \n",
       "1                      1028       1  \n",
       "2                      2259       1  \n",
       "3                       191       1  \n",
       "4                       191       1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_table(\"./spambase.txt\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colnames = list(data.columns.values)[:-1]\n",
    "X = data[colnames]\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "idx_train, idx_test = [], []\n",
    "for train, test in skf.split(X, y) :\n",
    "    idx_train.append(train)\n",
    "    idx_test.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'max_depth': 3, 'min_samples_leaf': 50, 'min_samples_split': 100},\n",
       " {'max_depth': 3, 'min_samples_leaf': 100, 'min_samples_split': 100},\n",
       " {'max_depth': 3, 'min_samples_leaf': 50, 'min_samples_split': 200},\n",
       " {'max_depth': 3, 'min_samples_leaf': 100, 'min_samples_split': 200},\n",
       " {'max_depth': 3, 'min_samples_leaf': 50, 'min_samples_split': 300},\n",
       " {'max_depth': 3, 'min_samples_leaf': 100, 'min_samples_split': 300},\n",
       " {'max_depth': 4, 'min_samples_leaf': 50, 'min_samples_split': 100},\n",
       " {'max_depth': 4, 'min_samples_leaf': 100, 'min_samples_split': 100},\n",
       " {'max_depth': 4, 'min_samples_leaf': 50, 'min_samples_split': 200},\n",
       " {'max_depth': 4, 'min_samples_leaf': 100, 'min_samples_split': 200},\n",
       " {'max_depth': 4, 'min_samples_leaf': 50, 'min_samples_split': 300},\n",
       " {'max_depth': 4, 'min_samples_leaf': 100, 'min_samples_split': 300}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth=[3, 4]\n",
    "min_samples_split=[100, 200, 300]\n",
    "min_samples_leaf=[50, 100]\n",
    "params = [dict(max_depth=d, min_samples_split=s, min_samples_leaf=l) \n",
    "          for d in max_depth for s in min_samples_split for l in min_samples_leaf]\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'min_samples_split': 100, 'min_samples_leaf': 50} 0.865237080857\n",
      "{'max_depth': 3, 'min_samples_split': 100, 'min_samples_leaf': 100} 0.857414292786\n",
      "{'max_depth': 3, 'min_samples_split': 200, 'min_samples_leaf': 50} 0.865237080857\n",
      "{'max_depth': 3, 'min_samples_split': 200, 'min_samples_leaf': 100} 0.857414292786\n",
      "{'max_depth': 3, 'min_samples_split': 300, 'min_samples_leaf': 50} 0.865237080857\n",
      "{'max_depth': 3, 'min_samples_split': 300, 'min_samples_leaf': 100} 0.854156963796\n",
      "{'max_depth': 4, 'min_samples_split': 100, 'min_samples_leaf': 50} 0.878262616095\n",
      "{'max_depth': 4, 'min_samples_split': 100, 'min_samples_leaf': 100} 0.861517085913\n",
      "{'max_depth': 4, 'min_samples_split': 200, 'min_samples_leaf': 50} 0.880438894658\n",
      "{'max_depth': 4, 'min_samples_split': 200, 'min_samples_leaf': 100} 0.861517085913\n",
      "{'max_depth': 4, 'min_samples_split': 300, 'min_samples_leaf': 50} 0.880003638946\n",
      "{'max_depth': 4, 'min_samples_split': 300, 'min_samples_leaf': 100} 0.868923521885\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "result_acc = []\n",
    "result_kfold = []\n",
    "for p in params :\n",
    "    clf = DecisionTreeClassifier(\n",
    "                            max_depth = p['max_depth'], \n",
    "                            min_samples_leaf = p['min_samples_leaf'],\n",
    "                            min_samples_split = p['min_samples_split']\n",
    "    )\n",
    "    tmp_acc = []\n",
    "    for k in range(len(idx_train)) :\n",
    "        clf.fit(X.iloc[idx_train[k]], y[idx_train[k]])\n",
    "        tmp_acc.append(clf.score(X.iloc[idx_test[k]], y[idx_test[k]]))\n",
    "    result_acc.append([p['max_depth'], p['min_samples_split'], p['min_samples_leaf']]+tmp_acc)\n",
    "    res = np.array(tmp_acc).mean()\n",
    "    result_kfold.append([p['max_depth'], p['min_samples_split'], p['min_samples_leaf'], res])\n",
    "    print(p, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>Fold1</th>\n",
       "      <th>Fold2</th>\n",
       "      <th>Fold3</th>\n",
       "      <th>Fold4</th>\n",
       "      <th>Fold5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.850163</td>\n",
       "      <td>0.879479</td>\n",
       "      <td>0.888165</td>\n",
       "      <td>0.914037</td>\n",
       "      <td>0.794342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.836048</td>\n",
       "      <td>0.874050</td>\n",
       "      <td>0.880565</td>\n",
       "      <td>0.902067</td>\n",
       "      <td>0.794342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>0.850163</td>\n",
       "      <td>0.879479</td>\n",
       "      <td>0.888165</td>\n",
       "      <td>0.914037</td>\n",
       "      <td>0.794342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>0.836048</td>\n",
       "      <td>0.874050</td>\n",
       "      <td>0.880565</td>\n",
       "      <td>0.902067</td>\n",
       "      <td>0.794342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>0.850163</td>\n",
       "      <td>0.879479</td>\n",
       "      <td>0.888165</td>\n",
       "      <td>0.914037</td>\n",
       "      <td>0.794342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>0.825190</td>\n",
       "      <td>0.868621</td>\n",
       "      <td>0.880565</td>\n",
       "      <td>0.902067</td>\n",
       "      <td>0.794342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.892508</td>\n",
       "      <td>0.895765</td>\n",
       "      <td>0.903366</td>\n",
       "      <td>0.898803</td>\n",
       "      <td>0.800871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.878393</td>\n",
       "      <td>0.890337</td>\n",
       "      <td>0.895765</td>\n",
       "      <td>0.894450</td>\n",
       "      <td>0.748640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>0.892508</td>\n",
       "      <td>0.895765</td>\n",
       "      <td>0.903366</td>\n",
       "      <td>0.906420</td>\n",
       "      <td>0.804135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>0.878393</td>\n",
       "      <td>0.890337</td>\n",
       "      <td>0.895765</td>\n",
       "      <td>0.894450</td>\n",
       "      <td>0.748640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>0.892508</td>\n",
       "      <td>0.895765</td>\n",
       "      <td>0.903366</td>\n",
       "      <td>0.914037</td>\n",
       "      <td>0.794342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>0.867535</td>\n",
       "      <td>0.884908</td>\n",
       "      <td>0.895765</td>\n",
       "      <td>0.902067</td>\n",
       "      <td>0.794342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_samples_split  min_samples_leaf     Fold1     Fold2  \\\n",
       "0           3                100                50  0.850163  0.879479   \n",
       "1           3                100               100  0.836048  0.874050   \n",
       "2           3                200                50  0.850163  0.879479   \n",
       "3           3                200               100  0.836048  0.874050   \n",
       "4           3                300                50  0.850163  0.879479   \n",
       "5           3                300               100  0.825190  0.868621   \n",
       "6           4                100                50  0.892508  0.895765   \n",
       "7           4                100               100  0.878393  0.890337   \n",
       "8           4                200                50  0.892508  0.895765   \n",
       "9           4                200               100  0.878393  0.890337   \n",
       "10          4                300                50  0.892508  0.895765   \n",
       "11          4                300               100  0.867535  0.884908   \n",
       "\n",
       "       Fold3     Fold4     Fold5  \n",
       "0   0.888165  0.914037  0.794342  \n",
       "1   0.880565  0.902067  0.794342  \n",
       "2   0.888165  0.914037  0.794342  \n",
       "3   0.880565  0.902067  0.794342  \n",
       "4   0.888165  0.914037  0.794342  \n",
       "5   0.880565  0.902067  0.794342  \n",
       "6   0.903366  0.898803  0.800871  \n",
       "7   0.895765  0.894450  0.748640  \n",
       "8   0.903366  0.906420  0.804135  \n",
       "9   0.895765  0.894450  0.748640  \n",
       "10  0.903366  0.914037  0.794342  \n",
       "11  0.895765  0.902067  0.794342  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame as df\n",
    "colnames = ['max_depth', 'min_samples_split', 'min_samples_leaf', 'Fold1', 'Fold2', 'Fold3', 'Fold4', 'Fold5']\n",
    "result_acc = df(result_acc, columns=colnames)\n",
    "result_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>Acc_Fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.865237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.857414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>0.865237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>0.857414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>0.865237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>0.854157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.878263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.861517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>0.880439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>0.861517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>0.880004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>0.868924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_samples_split  min_samples_leaf  Acc_Fold\n",
       "0           3                100                50  0.865237\n",
       "1           3                100               100  0.857414\n",
       "2           3                200                50  0.865237\n",
       "3           3                200               100  0.857414\n",
       "4           3                300                50  0.865237\n",
       "5           3                300               100  0.854157\n",
       "6           4                100                50  0.878263\n",
       "7           4                100               100  0.861517\n",
       "8           4                200                50  0.880439\n",
       "9           4                200               100  0.861517\n",
       "10          4                300                50  0.880004\n",
       "11          4                300               100  0.868924"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames= colnames[:3] + ['Acc_Fold']\n",
    "result_kfold = df(result_kfold, columns=colnames)\n",
    "result_kfold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 평균적으로 가장 정확도가 높은 조건으로 전체 데이터를 이용해서 decision tree를 학습하고 그 결과 tree를 그리시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>Acc_Fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>0.880439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  min_samples_split  min_samples_leaf  Acc_Fold\n",
       "8          4                200                50  0.880439"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = result_kfold[result_kfold['Acc_Fold']==np.max(result_kfold['Acc_Fold'])]\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4, 'min_samples_leaf': 50, 'min_samples_split': 200}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_param = params[res_df.index.values[0]]\n",
    "res_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=50,\n",
       "            min_samples_split=200, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(\n",
    "                            max_depth = res_param['max_depth'], \n",
    "                            min_samples_leaf = res_param['min_samples_leaf'],\n",
    "                            min_samples_split = res_param['min_samples_split']\n",
    "    )\n",
    "clf.fit(X,y)\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) sklearn.model_selection.train_test_split을 이용해서 데이터를 train set과 test set (validation set)으로 나누고자 한다. 먼저 주어진 데이터를 불러와 input에 해당하는 X와 output 값만 담고 있는 y 변수를 생성하고 여기서부터 train_test_split를 이용해서 Xtrain, Xtest, ytrain, ytest를 얻으시오. 이 때 test_size=0.2, stratify=y, random_state=150으로 설정하시오. Xtrain에 들어있는 데이터 중 맨 위에 있는 5개 데이터와 Xtest에 들어있는 데이터 중 맨 위에 있는 5개 데이터를 jupyter notebook 화면에 print하시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alreadi</th>\n",
       "      <th>also</th>\n",
       "      <th>alway</th>\n",
       "      <th>amp</th>\n",
       "      <th>anyth</th>\n",
       "      <th>around</th>\n",
       "      <th>ask</th>\n",
       "      <th>award</th>\n",
       "      <th>babe</th>\n",
       "      <th>back</th>\n",
       "      <th>...</th>\n",
       "      <th>win</th>\n",
       "      <th>wish</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>would</th>\n",
       "      <th>www</th>\n",
       "      <th>ya</th>\n",
       "      <th>ye</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3205</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3923</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      alreadi  also  alway  amp  anyth  around  ask  award  babe  back  ...   \\\n",
       "989         0     0      0    0      0       0    0      0     0     0  ...    \n",
       "2140        0     0      0    0      0       0    0      0     0     0  ...    \n",
       "3205        0     0      0    1      0       1    0      0     0     0  ...    \n",
       "1263        0     0      0    0      0       0    0      0     0     0  ...    \n",
       "3923        0     0      0    0      0       0    0      0     0     0  ...    \n",
       "\n",
       "      win  wish  word  work  would  www  ya  ye  yeah  year  \n",
       "989     0     0     0     0      0    0   0   0     0     0  \n",
       "2140    0     0     0     0      0    0   0   0     0     0  \n",
       "3205    0     0     0     0      0    0   0   0     0     0  \n",
       "1263    0     0     0     0      0    0   0   0     0     0  \n",
       "3923    0     0     0     0      0    0   0   0     0     0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./spam_sms.csv')\n",
    "\n",
    "colnames = list(data.columns.values)[:-1]\n",
    "X = data[colnames]\n",
    "y = data['target']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.32, random_state=150, stratify=y\n",
    ")\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alreadi</th>\n",
       "      <th>also</th>\n",
       "      <th>alway</th>\n",
       "      <th>amp</th>\n",
       "      <th>anyth</th>\n",
       "      <th>around</th>\n",
       "      <th>ask</th>\n",
       "      <th>award</th>\n",
       "      <th>babe</th>\n",
       "      <th>back</th>\n",
       "      <th>...</th>\n",
       "      <th>win</th>\n",
       "      <th>wish</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>would</th>\n",
       "      <th>www</th>\n",
       "      <th>ya</th>\n",
       "      <th>ye</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3881</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3889</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4437</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      alreadi  also  alway  amp  anyth  around  ask  award  babe  back  ...   \\\n",
       "3881        0     0      0    0      0       1    0      0     0     0  ...    \n",
       "283         0     0      0    0      0       0    0      0     0     0  ...    \n",
       "1134        0     0      0    0      0       0    0      0     0     0  ...    \n",
       "3889        0     0      0    0      0       0    0      0     0     0  ...    \n",
       "4437        0     0      0    0      0       0    0      0     0     0  ...    \n",
       "\n",
       "      win  wish  word  work  would  www  ya  ye  yeah  year  \n",
       "3881    0     0     0     0      0    0   0   0     0     0  \n",
       "283     0     0     0     0      0    0   0   0     0     0  \n",
       "1134    0     0     0     0      0    0   0   0     0     0  \n",
       "3889    0     0     0     0      0    0   0   0     0     0  \n",
       "4437    0     0     0     0      0    0   0   0     0     0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Multinomial naïve Bayes 모형을 이용해서 세팅이 변경없이 train set으로 학습을 하고 test set을 이용해서 정확도(accuracy), recall, precision, f1 measure 값을 구하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.96880733944954134, 'precision': 0.87854251012145745, 'recall': 0.91176470588235292, 'f1_score': 0.89484536082474231}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "res = dict(\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred),\n",
    "    precision = metrics.precision_score(y_test, y_pred),\n",
    "    recall = metrics.recall_score(y_test, y_pred),\n",
    "    f1_score = metrics.f1_score(y_test, y_pred)\n",
    ")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 학습된 Multinomial naïve Bayes 모형으로부터 서로 다른 두 group(스팸 SMS와 스팸이 아닌 SMS)일 확률을 높이는데 가장 기여를 많이 하는 단어 상위 10개씩을 찾으시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res_df = df({'feature':X_train.columns.values,\n",
    "            'log_prob_0' : clf.feature_log_prob_[0],\n",
    "             'log_prob_1' : clf.feature_log_prob_[1],\n",
    "             'prob_0' : np.exp(clf.feature_log_prob_[0]),\n",
    "             'prob_1' : np.exp(clf.feature_log_prob_[1])\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>log_prob_0</th>\n",
       "      <th>log_prob_1</th>\n",
       "      <th>prob_0</th>\n",
       "      <th>prob_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alreadi</td>\n",
       "      <td>-5.230039</td>\n",
       "      <td>-7.453562</td>\n",
       "      <td>0.005353</td>\n",
       "      <td>0.000579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>also</td>\n",
       "      <td>-5.432563</td>\n",
       "      <td>-7.048097</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.000869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alway</td>\n",
       "      <td>-5.858647</td>\n",
       "      <td>-8.146709</td>\n",
       "      <td>0.002855</td>\n",
       "      <td>0.000290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amp</td>\n",
       "      <td>-5.230039</td>\n",
       "      <td>-8.146709</td>\n",
       "      <td>0.005353</td>\n",
       "      <td>0.000290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anyth</td>\n",
       "      <td>-5.246846</td>\n",
       "      <td>-8.146709</td>\n",
       "      <td>0.005264</td>\n",
       "      <td>0.000290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature  log_prob_0  log_prob_1    prob_0    prob_1\n",
       "0  alreadi   -5.230039   -7.453562  0.005353  0.000579\n",
       "1     also   -5.432563   -7.048097  0.004372  0.000869\n",
       "2    alway   -5.858647   -8.146709  0.002855  0.000290\n",
       "3      amp   -5.230039   -8.146709  0.005353  0.000290\n",
       "4    anyth   -5.246846   -8.146709  0.005264  0.000290"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>log_prob_0</th>\n",
       "      <th>prob_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>go</td>\n",
       "      <td>-3.634024</td>\n",
       "      <td>0.026410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>get</td>\n",
       "      <td>-3.763701</td>\n",
       "      <td>0.023198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>gt</td>\n",
       "      <td>-3.869062</td>\n",
       "      <td>0.020878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>lt</td>\n",
       "      <td>-3.881965</td>\n",
       "      <td>0.020610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>call</td>\n",
       "      <td>-3.935311</td>\n",
       "      <td>0.019540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>come</td>\n",
       "      <td>-4.016115</td>\n",
       "      <td>0.018023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ok</td>\n",
       "      <td>-4.021078</td>\n",
       "      <td>0.017934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>ur</td>\n",
       "      <td>-4.061693</td>\n",
       "      <td>0.017220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>love</td>\n",
       "      <td>-4.098636</td>\n",
       "      <td>0.016595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>day</td>\n",
       "      <td>-4.109447</td>\n",
       "      <td>0.016417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  log_prob_0    prob_0\n",
       "43       go   -3.634024  0.026410\n",
       "41      get   -3.763701  0.023198\n",
       "48       gt   -3.869062  0.020878\n",
       "76       lt   -3.881965  0.020610\n",
       "12     call   -3.935311  0.019540\n",
       "22     come   -4.016115  0.018023\n",
       "99       ok   -4.021078  0.017934\n",
       "152      ur   -4.061693  0.017220\n",
       "75     love   -4.098636  0.016595\n",
       "27      day   -4.109447  0.016417"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.sort_values('log_prob_0', ascending=False)[['feature', 'log_prob_0', 'prob_0']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>log_prob_1</th>\n",
       "      <th>prob_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>call</td>\n",
       "      <td>-2.586027</td>\n",
       "      <td>0.075319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>free</td>\n",
       "      <td>-3.022745</td>\n",
       "      <td>0.048667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>txt</td>\n",
       "      <td>-3.248869</td>\n",
       "      <td>0.038818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>ur</td>\n",
       "      <td>-3.483270</td>\n",
       "      <td>0.030707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>text</td>\n",
       "      <td>-3.635850</td>\n",
       "      <td>0.026362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>mobil</td>\n",
       "      <td>-3.635850</td>\n",
       "      <td>0.026362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>stop</td>\n",
       "      <td>-3.704058</td>\n",
       "      <td>0.024623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>repli</td>\n",
       "      <td>-3.815976</td>\n",
       "      <td>0.022016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>www</td>\n",
       "      <td>-3.815976</td>\n",
       "      <td>0.022016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>claim</td>\n",
       "      <td>-3.842644</td>\n",
       "      <td>0.021437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  log_prob_1    prob_1\n",
       "12     call   -2.586027  0.075319\n",
       "39     free   -3.022745  0.048667\n",
       "150     txt   -3.248869  0.038818\n",
       "152      ur   -3.483270  0.030707\n",
       "139    text   -3.635850  0.026362\n",
       "86    mobil   -3.635850  0.026362\n",
       "134    stop   -3.704058  0.024623\n",
       "114   repli   -3.815976  0.022016\n",
       "170     www   -3.815976  0.022016\n",
       "18    claim   -3.842644  0.021437"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.sort_values('log_prob_1', ascending=False)[['feature', 'log_prob_1', 'prob_1']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrmae을 사용하지 않고 찾는 방법\n",
    "[numpy.argsort](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argsort.html) 사용, 이때 값 구성에 차이가 다소 있음.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: ['go' 'get' 'call' 'come' 'ok' 'gt' 'lt' 'know' 'day' 'good']\n",
      "Class 1: ['call' 'free' 'txt' 'mobil' 'ur' 'text' 'www' 'repli' 'claim' 'stop']\n"
     ]
    }
   ],
   "source": [
    "print(\"Class 0: {}\".format(X_train.columns.values[np.argsort(clf.feature_log_prob_[0])[-10:][::-1]]))\n",
    "print(\"Class 1: {}\".format(X_train.columns.values[np.argsort(clf.feature_log_prob_[1])[-10:][::-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) 학습된 Multinomial naïve Bayes 모형에서 서로 다른 두 group에 대해서 개별 단어의 $p_i  (i=\\{1,…,175\\})$ 값들의 히스토그램을 그리시오. 이 때 히스토그램을 그리기 위한 막대의 수는 30으로 하시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 16.,   9.,   7.,  33.,  24.,  23.,  10.,  10.,   9.,   9.,   6.,\n",
       "          0.,   3.,   0.,   0.,   1.,   4.,   0.,   3.,   1.,   2.,   0.,\n",
       "          1.,   2.,   0.,   0.,   1.,   0.,   0.,   1.]),\n",
       " array([ 1.00008923,  1.0009783 ,  1.00186738,  1.00275646,  1.00364553,\n",
       "         1.00453461,  1.00542369,  1.00631276,  1.00720184,  1.00809092,\n",
       "         1.00898   ,  1.00986907,  1.01075815,  1.01164723,  1.0125363 ,\n",
       "         1.01342538,  1.01431446,  1.01520353,  1.01609261,  1.01698169,\n",
       "         1.01787076,  1.01875984,  1.01964892,  1.020538  ,  1.02142707,\n",
       "         1.02231615,  1.02320523,  1.0240943 ,  1.02498338,  1.02587246,\n",
       "         1.02676153]),\n",
       " <a list of 30 Patch objects>)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbCY2uHfUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1128c39e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.exp(res_df['prob_0']), bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 101.,   21.,   12.,   10.,    6.,    9.,    4.,    2.,    3.,\n",
       "           1.,    2.,    1.,    0.,    0.,    0.,    1.,    0.,    0.,\n",
       "           0.,    1.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    1.]),\n",
       " array([ 1.00028973,  1.00288766,  1.00548559,  1.00808352,  1.01068146,\n",
       "         1.01327939,  1.01587732,  1.01847525,  1.02107318,  1.02367111,\n",
       "         1.02626905,  1.02886698,  1.03146491,  1.03406284,  1.03666077,\n",
       "         1.0392587 ,  1.04185664,  1.04445457,  1.0470525 ,  1.04965043,\n",
       "         1.05224836,  1.05484629,  1.05744423,  1.06004216,  1.06264009,\n",
       "         1.06523802,  1.06783595,  1.07043388,  1.07303182,  1.07562975,\n",
       "         1.07822768]),\n",
       " <a list of 30 Patch objects>)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nroXeJgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1172e6748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.exp(res_df['prob_1']), bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Bernoulli naïve Bayes 모형을 이용해서 세팅 변경 없이 train set으로 학습을 하고 test set을 이용해서 정확도(accuracy), recall, precision, f1 measure 값을 구하시오. (2)의 결과와 비교하여 어느 쪽이 더 나은 모형인지 설명하시오. 이 결과로부터 알 수 있는 사실은 무엇인가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.97675840978593276, 'precision': 0.94247787610619471, 'recall': 0.89495798319327735, 'f1_score': 0.91810344827586199}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "res = dict(\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred),\n",
    "    precision = metrics.precision_score(y_test, y_pred),\n",
    "    recall = metrics.recall_score(y_test, y_pred),\n",
    "    f1_score = metrics.f1_score(y_test, y_pred)\n",
    ")\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
